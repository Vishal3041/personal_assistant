{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a4b928-689d-405f-856c-28c43c0e974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.46.3)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
      "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.20.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.6)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2023.11.17)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.1.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.21)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.146)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (2.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install torch transformers peft datasets sentence-transformers pinecone-client langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4793ed12-d624-4cf2-91dc-6d05c4ec0f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 12:23:09.638928: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-28 12:23:09.661015: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-28 12:23:09.661033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-28 12:23:09.661796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-28 12:23:09.666290: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
    "from datetime import datetime\n",
    "import pinecone\n",
    "import re\n",
    "\n",
    "# Load dataset\n",
    "csv_file = \"/app/all_merged_file.csv\"  # Replace with your dataset path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Preprocess the \"Watched At\" column to extract date\n",
    "def preprocess_date(row):\n",
    "    try:\n",
    "        return datetime.strptime(row[\"Watched At\"], \"%b %d, %Y\").date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "df[\"Watched Date\"] = df.apply(preprocess_date, axis=1)\n",
    "\n",
    "# Format the dataset for fine-tuning\n",
    "def preprocess_row(row):\n",
    "    return {\n",
    "        \"input_text\": f\"Title: {row['Title']} Category: {row['Category']} Watched at: {row['Watched At']}\",\n",
    "        \"output_text\": f\"Video Link: {row['Video Link']}\"\n",
    "    }\n",
    "\n",
    "formatted_data = df.apply(preprocess_row, axis=1).tolist()\n",
    "dataset = Dataset.from_list(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0228cdd7-1cb3-475b-8ec2-b2802fba5338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb6dd2e-9e59-4d60-8729-fff76e7f0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your token here\n",
    "hf_token = \"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\"\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa776dad-1bb5-470c-af80-0bc19e4dd097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 25395\n",
      "Validation dataset size: 5442\n",
      "Test dataset size: 5442\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Assuming 'dataset' is a Hugging Face Dataset object\n",
    "# Split the dataset into training, validation, and test sets using the Hugging Face dataset method\n",
    "train_data = dataset.train_test_split(test_size=0.3, seed=42)  # Split 30% as the temporary data\n",
    "val_data, test_data = train_data['test'].train_test_split(test_size=0.5, seed=42).values()  # Split the temp data into 50% validation and 50% test\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = train_data['train']\n",
    "val_dataset = val_data\n",
    "test_dataset = test_data\n",
    "\n",
    "# Optionally, you can check the split sizes\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e95e022-eac2-47e4-b80e-eee46ed96b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the pretrained model and tokenizer\n",
    "model_id = \"tiiuae/falcon-rw-1b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71132cd2-e0c0-4986-8b1e-512dab7d9ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalconForCausalLM(\n",
      "  (transformer): FalconModel(\n",
      "    (word_embeddings): Embedding(50304, 2048)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x FalconDecoderLayer(\n",
      "        (self_attention): FalconAttention(\n",
      "          (query_key_value): FalconLinear(in_features=2048, out_features=6144, bias=True)\n",
      "          (dense): FalconLinear(in_features=2048, out_features=2048, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): FalconMLP(\n",
      "          (dense_h_to_4h): FalconLinear(in_features=2048, out_features=8192, bias=True)\n",
      "          (act): GELUActivation()\n",
      "          (dense_4h_to_h): FalconLinear(in_features=8192, out_features=2048, bias=True)\n",
      "        )\n",
      "        (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "    (rotary_emb): FalconRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013981cc-1144-4c9d-bf52-2242f6cbe1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# LoRA configuration for Falcon\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"self_attention.query_key_value\"],  # Correct target for Falcon\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d54942-48f3-4875-97cb-0e317f90ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): FalconForCausalLM(\n",
      "      (transformer): FalconModel(\n",
      "        (word_embeddings): Embedding(50304, 2048)\n",
      "        (h): ModuleList(\n",
      "          (0-23): 24 x FalconDecoderLayer(\n",
      "            (self_attention): FalconAttention(\n",
      "              (query_key_value): lora.Linear(\n",
      "                (base_layer): FalconLinear(in_features=2048, out_features=6144, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=6144, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (dense): FalconLinear(in_features=2048, out_features=2048, bias=True)\n",
      "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (mlp): FalconMLP(\n",
      "              (dense_h_to_4h): FalconLinear(in_features=2048, out_features=8192, bias=True)\n",
      "              (act): GELUActivation()\n",
      "              (dense_4h_to_h): FalconLinear(in_features=8192, out_features=2048, bias=True)\n",
      "            )\n",
      "            (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "            (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (rotary_emb): FalconRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04b1c8f-8b12-4351-8f1b-26c516c64c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Define a data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e37ec6-1481-49ee-90c9-a89744237abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the tokenizer has a pad token, and set it if not\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c07c2f-3e58-4f39-b4c8-a1066cfc4d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82004d2a56d24d92bc4234e1a44a867e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25395 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecad0105b84445c91e3e73e648ff9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the datase\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"input_text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "    outputs = tokenizer(examples[\"output_text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = outputs[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_tokenized_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf34959-c233-4a07-9491-134d3e30918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701c0a5e-3fc6-450a-a968-8718ee283810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9522' max='9522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9522/9522 1:12:34, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.103603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.102058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.101643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9522, training_loss=0.12454791396317975, metrics={'train_runtime': 4355.5694, 'train_samples_per_second': 17.491, 'train_steps_per_second': 2.186, 'total_flos': 2.8356446964311654e+17, 'train_loss': 0.12454791396317975, 'epoch': 2.999645599527466})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Fine-tuning arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,  # Enables mixed precision\n",
    "    per_device_train_batch_size=1,  # Decrease batch size\n",
    "    gradient_accumulation_steps=8,  # Accumulate gradients for larger effective batch size\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,  # Save space\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=val_tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d697df-a8b5-4811-a298-1ee96baf5354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model_new/tokenizer_config.json',\n",
       " './fine_tuned_model_new/special_tokens_map.json',\n",
       " './fine_tuned_model_new/vocab.json',\n",
       " './fine_tuned_model_new/merges.txt',\n",
       " './fine_tuned_model_new/added_tokens.json',\n",
       " './fine_tuned_model_new/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_model_new\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "763f2593-10f0-42ef-b75f-ef5e502242ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Once upon a time, there was a little girl who lived in a little house. She had a little brother and a little sister. She had a little dog and a little cat. She had a little brother and a little sister. She had a'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load fine-tuned model\n",
    "fine_tuned_model_path = \"./fine_tuned_model_new\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(fine_tuned_model_path)\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Create a pipeline for generation with the device argument\n",
    "rag_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Example usage of the pipeline\n",
    "input_text = \"Once upon a time\"\n",
    "generated_text = rag_pipeline(input_text, max_length=50)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "416b8d88-07c4-4d99-bbc3-f6a02f56dbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: gCCVsvgR2KU\n",
      "Title: #10 Python Tutorial for Beginners | Data Types in Python\n",
      "Category: Science & Technology\n",
      "Video Link: https://www.youtube.com/watch?v=gCCVsvgR2KU\n",
      "-----\n",
      "Video ID: hEgO047GxaQ\n",
      "Title: #1 Python Tutorial for Beginners | Introduction to Python\n",
      "Category: Science & Technology\n",
      "Video Link: https://www.youtube.com/watch?v=hEgO047GxaQ\n",
      "-----\n",
      "Video ID: DWgzHbglNIo\n",
      "Title: #3 Python Tutorial for Beginners | Getting Started with Python\n",
      "Category: Science & Technology\n",
      "Video Link: https://www.youtube.com/watch?v=DWgzHbglNIo\n",
      "-----\n",
      "Video ID: _t2GVaQasRY\n",
      "Title: Data Structures & Algorithms Tutorial in Python #1 - What are data structures?\n",
      "Category: Education\n",
      "Video Link: https://www.youtube.com/watch?v=_t2GVaQasRY\n",
      "-----\n",
      "Video ID: pkYVOmU3MgA\n",
      "Title: Data Structures and Algorithms in Python - Full Course for Beginners\n",
      "Category: Education\n",
      "Video Link: https://www.youtube.com/watch?v=pkYVOmU3MgA\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone using the new API\n",
    "pc = Pinecone(api_key=\"85e39b43-9316-4d8b-b684-eb46542c34ef\", environment=\"us-east-1\")\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"youtube-data-index\"\n",
    "\n",
    "# Access the existing Pinecone index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Embedding Model from Sentence-Transformers\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Example query to retrieve the most similar video based on a query\n",
    "query = \"Python tutorial on data science\"\n",
    "query_vector = embedding_model.encode(query)\n",
    "\n",
    "# Convert the numpy array to a list of floats\n",
    "query_vector = query_vector.tolist()\n",
    "\n",
    "# Query Pinecone index for the most similar vector\n",
    "results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
    "\n",
    "# Display results\n",
    "for result in results['matches']:\n",
    "    print(f\"Video ID: {result['id']}\")\n",
    "    print(f\"Title: {result['metadata']['Title']}\")\n",
    "    print(f\"Category: {result['metadata']['Category']}\")\n",
    "    print(f\"Video Link: {result['metadata']['Video Link']}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fecd84c-90b2-4ea0-acaf-2e564138c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_filtered_query(query, filter_conditions=None, query_vector=None):\n",
    "    \"\"\"\n",
    "    Perform a Pinecone query with combined filters and augment the result with RAG.\n",
    "    \"\"\"\n",
    "    if filter_conditions is None:\n",
    "        filter_conditions = {}\n",
    "\n",
    "    # Use query_vector for title-based search, or default vector for filter-only queries\n",
    "    if query_vector is None:\n",
    "        query_vector = [0.0] * 384  # Dummy vector for metadata-only filtering\n",
    "\n",
    "    # Query Pinecone with combined filters\n",
    "    results = index.query(\n",
    "        vector=query_vector,\n",
    "        top_k=5,\n",
    "        include_metadata=True,\n",
    "        filter=filter_conditions\n",
    "    )\n",
    "\n",
    "    # Construct context with titles and video links, filtered by category\n",
    "    context = \"\\n\".join([\n",
    "        f\"{res['metadata']['Title']} ({res['metadata']['Watched At']}): {res['metadata']['Video Link']}\"\n",
    "        for res in results[\"matches\"]\n",
    "        if filter_conditions.get(\"Category\", \"\").lower() in res['metadata'].get(\"Category\", \"\").lower()\n",
    "    ])\n",
    "\n",
    "    # Limit context length to avoid exceeding model limits\n",
    "    max_context_length = 300  # Adjust based on model's input size\n",
    "    truncated_context = context[:max_context_length]\n",
    "\n",
    "    # Augment the query with the context\n",
    "    augmented_query = f\"Here are some videos in the category '{filter_conditions.get('Category', 'General')}':\\n{truncated_context}\\n\\nQuery: {query}\"\n",
    "    \n",
    "    # Debug: Print the augmented query\n",
    "    print(f\"Augmented Query:\\n{augmented_query}\\n\")\n",
    "\n",
    "    # Generate response\n",
    "    response = rag_pipeline(augmented_query, max_new_tokens=100, num_return_sequences=1)\n",
    "    \n",
    "    # Handle empty or nonsensical responses\n",
    "    if response and response[0][\"generated_text\"].strip():\n",
    "        return response[0][\"generated_text\"]\n",
    "    else:\n",
    "        return \"No relevant videos found in the specified category or time range.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e805a6b0-0467-40d7-9eb0-6bed8f2f0af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Query:\n",
      "Here are some videos in the category 'Science & Technology':\n",
      "Building a Recommendation System in Python (Nov 5, 2023, 1:36:59â€¯PM PDT): https://www.youtube.com/watch?v=G4MBc40rQ2k\n",
      "A day lasting 365 days ðŸ˜¨ #space #astronomy #universe (Sep 10, 2024, 7:48:00â€¯AM PST): https://www.youtube.com/watch?v=6B3uP1HHVZ8\n",
      "Architecture Interior Design  knows a guy 29s (Watche\n",
      "\n",
      "Query: Show me videos under Science & Technology\n",
      "\n",
      "Here are some videos in the category 'Science & Technology':\n",
      "Building a Recommendation System in Python (Nov 5, 2023, 1:36:59â€¯PM PDT): https://www.youtube.com/watch?v=G4MBc40rQ2k\n",
      "A day lasting 365 days ðŸ˜¨ #space #astronomy #universe (Sep 10, 2024, 7:48:00â€¯AM PST): https://www.youtube.com/watch?v=6B3uP1HHVZ8\n",
      "Architecture Interior Design  knows a guy 29s (Watche\n",
      "\n",
      "Query: Show me videos under Science & TechnologyThe.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "The.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_rag_query(query):\n",
    "    \"\"\"\n",
    "    Perform a RAG query by detecting query type and routing to the appropriate handler.\n",
    "    Supports combined queries (date + category + title).\n",
    "    \"\"\"\n",
    "    # Predefined categories for detection (extend as needed)\n",
    "    categories = [\n",
    "        \"Science & Technology\",\n",
    "        \"Education\",\n",
    "        \"News & Politics\",\n",
    "        \"Autos & Vehicles\"\n",
    "    ]\n",
    "\n",
    "    filter_conditions = {}\n",
    "    query_vector = None\n",
    "\n",
    "    # Detect date in query\n",
    "    date_match = re.search(r'\\b(\\d{1,2}(st|nd|rd|th)?\\s+\\w+\\s+\\d{4})\\b', query, re.IGNORECASE)\n",
    "    if date_match:\n",
    "        date_query = date_match.group(1)\n",
    "        date_obj = datetime.strptime(date_query, \"%B %d, %Y\").date()\n",
    "        filter_conditions[\"Watched Date\"] = str(date_obj)\n",
    "    \n",
    "    # Detect category in query\n",
    "    for category in categories:\n",
    "        if category.lower() in query.lower():\n",
    "            filter_conditions[\"Category\"] = category\n",
    "    \n",
    "    # Detect title keywords (if no explicit date/category filter)\n",
    "    if len(filter_conditions) == 0 or \"title\" in query.lower():\n",
    "        query_vector = embedding_model.encode(query).tolist()\n",
    "\n",
    "    # Pass combined filters and query vector to `perform_filtered_query`\n",
    "    return perform_filtered_query(query, filter_conditions=filter_conditions, query_vector=query_vector)\n",
    "\n",
    "# Example usage\n",
    "query = \"Show me videos under Science & Technology\"\n",
    "response = perform_rag_query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718afa4-f492-4ea8-b555-9325d9f8c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_rag_query(query):\n",
    "    # Encode the query\n",
    "    query_vector = embedding_model.encode(query).tolist()\n",
    "\n",
    "    # Retrieve top matches\n",
    "    results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
    "    context = \"\\n\".join([f\"{res['metadata']['Title']}: {res['metadata']['Video Link']}\" for res in results[\"matches\"]])\n",
    "\n",
    "    # Augment query with context\n",
    "    augmented_query = f\"Context: {context}\\n\\nQuery: {query}\"\n",
    "\n",
    "    # Generate response with max_new_tokens instead of max_length\n",
    "    response = rag_pipeline(augmented_query, max_new_tokens=100, num_return_sequences=1)\n",
    "    return response[0][\"generated_text\"]\n",
    "\n",
    "# Example query\n",
    "query = \"Python tutorial on data science\"\n",
    "response = perform_rag_query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de924a03-e82a-42e0-91ee-3d0979026166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split dataset for training, validation, and testing\n",
    "# train_data = dataset.train_test_split(test_size=0.3, seed=42)\n",
    "# val_data, test_data = train_data['test'].train_test_split(test_size=0.5, seed=42).values()\n",
    "# train_dataset, val_dataset, test_dataset = train_data['train'], val_data, test_data\n",
    "\n",
    "# # Initialize Pinecone\n",
    "# pinecone.init(api_key=\"your_pinecone_api_key\", environment=\"us-east-1\")  # Replace with your API key\n",
    "# index_name = \"youtube-index\"\n",
    "\n",
    "# if index_name not in pinecone.list_indexes():\n",
    "#     pinecone.create_index(index_name, dimension=384, metric=\"cosine\")\n",
    "\n",
    "# index = pinecone.Index(index_name)\n",
    "\n",
    "# # Embedding model for Pinecone\n",
    "# embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# # Populate Pinecone index with refined metadata\n",
    "# for i, row in df.iterrows():\n",
    "#     video_data = f\"Title: {row['Title']}, Category: {row['Category']}, Watched at: {row['Watched At']}\"\n",
    "#     vector = embedding_model.encode(video_data)\n",
    "#     index.upsert([(row['Video ID'], vector, {\n",
    "#         \"Title\": row[\"Title\"],\n",
    "#         \"Category\": row[\"Category\"],\n",
    "#         \"Watched At\": row[\"Watched At\"],\n",
    "#         \"Watched Date\": str(row[\"Watched Date\"]),\n",
    "#         \"Video Link\": row[\"Video Link\"]\n",
    "#     })])\n",
    "\n",
    "# print(\"Pinecone index populated.\")\n",
    "\n",
    "# # Load pretrained Falcon model\n",
    "# model_id = \"tiiuae/falcon-rw-1b\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# # Apply LoRA to the model\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"self_attention.query_key_value\"],\n",
    "#     lora_dropout=0.1,\n",
    "# )\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # Tokenize dataset\n",
    "# def tokenize_function(examples):\n",
    "#     inputs = tokenizer(examples[\"input_text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "#     outputs = tokenizer(examples[\"output_text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "#     inputs[\"labels\"] = outputs[\"input_ids\"]\n",
    "#     return inputs\n",
    "\n",
    "# tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Data collator\n",
    "# data_collator = DataCollatorForSeq2Seq(\n",
    "#     tokenizer=tokenizer,\n",
    "#     model=model,\n",
    "#     padding=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# )\n",
    "\n",
    "# # Training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     fp16=True,\n",
    "#     per_device_train_batch_size=1,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     num_train_epochs=3,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=10,\n",
    "#     save_total_limit=2,\n",
    "#     load_best_model_at_end=True,\n",
    "# )\n",
    "\n",
    "# # Initialize trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_train,\n",
    "#     eval_dataset=tokenized_val,\n",
    "#     data_collator=data_collator,\n",
    "# )\n",
    "\n",
    "# # Fine-tune the model\n",
    "# trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "# model.save_pretrained(\"./fine_tuned_model\")\n",
    "# tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "# Load fine-tuned model into a pipeline\n",
    "# fine_tuned_model_path = \"./fine_tuned_model_new\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(fine_tuned_model_path)\n",
    "# model = AutoModelForCausalLM.from_pretrained(fine_tuned_model_path)\n",
    "# rag_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# # Query functions\n",
    "# def perform_filtered_query(query, filter_conditions=None, query_vector=None):\n",
    "#     \"\"\"\n",
    "#     Perform a Pinecone query with combined filters and augment the result with RAG.\n",
    "#     \"\"\"\n",
    "#     if filter_conditions is None:\n",
    "#         filter_conditions = {}\n",
    "\n",
    "#     # Use query_vector for title-based search, or default vector for filter-only queries\n",
    "#     if query_vector is None:\n",
    "#         query_vector = [0.0] * 384  # Dummy vector for metadata-only filtering\n",
    "\n",
    "#     # Query Pinecone with combined filters\n",
    "#     results = index.query(\n",
    "#         vector=query_vector,\n",
    "#         top_k=5,\n",
    "#         include_metadata=True,\n",
    "#         filter=filter_conditions\n",
    "#     )\n",
    "\n",
    "#     # Construct context with titles and video links\n",
    "#     context = \"\\n\".join([\n",
    "#         f\"{res['metadata']['Title']} ({res['metadata']['Watched At']}): {res['metadata']['Video Link']}\"\n",
    "#         for res in results[\"matches\"]\n",
    "#     ])\n",
    "\n",
    "#     # Augment the query with the context\n",
    "#     augmented_query = f\"Context: {context}\\n\\nQuery: {query}\"\n",
    "#     response = rag_pipeline(augmented_query, max_new_tokens=100, num_return_sequences=1)\n",
    "#     return response[0][\"generated_text\"]\n",
    "\n",
    "# def perform_rag_query(query):\n",
    "#     \"\"\"\n",
    "#     Perform a RAG query by detecting query type and routing to the appropriate handler.\n",
    "#     Supports combined queries (date + category + title).\n",
    "#     \"\"\"\n",
    "#     # Predefined categories for detection (extend as needed)\n",
    "#     categories = [\n",
    "#         \"Science & Technology\",\n",
    "#         \"Education\",\n",
    "#         \"News & Politics\",\n",
    "#         \"Autos & Vehicles\"\n",
    "#     ]\n",
    "\n",
    "#     filter_conditions = {}\n",
    "#     query_vector = None\n",
    "\n",
    "#     # Detect date in query\n",
    "#     date_match = re.search(r'\\b(\\d{1,2}(st|nd|rd|th)?\\s+\\w+\\s+\\d{4})\\b', query, re.IGNORECASE)\n",
    "#     if date_match:\n",
    "#         date_query = date_match.group(1)\n",
    "#         date_obj = datetime.strptime(date_query, \"%B %d, %Y\").date()\n",
    "#         filter_conditions[\"Watched Date\"] = str(date_obj)\n",
    "    \n",
    "#     # Detect category in query\n",
    "#     for category in categories:\n",
    "#         if category.lower() in query.lower():\n",
    "#             filter_conditions[\"Category\"] = category\n",
    "    \n",
    "#     # Detect title keywords (if no explicit date/category filter)\n",
    "#     if len(filter_conditions) == 0 or \"title\" in query.lower():\n",
    "#         query_vector = embedding_model.encode(query).tolist()\n",
    "\n",
    "#     # Pass combined filters and query vector to `perform_filtered_query`\n",
    "#     return perform_filtered_query(query, filter_conditions=filter_conditions, query_vector=query_vector)\n",
    "\n",
    "# # Example usage\n",
    "# query = \"Show me the videos I watched under Science & Technology on 10th October 2024\"\n",
    "# response = perform_rag_query(query)\n",
    "# print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
